{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_foster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('foster-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status of the youth is: in\n",
      "The age of the youth is: 15\n",
      "The race of the youth is: major\n",
      "The casegoal of the youth is: Empty\n",
      "Current reward is: 0\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LTFC', 16, 'major', 0.1, 'in']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step('a_LTFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status of the youth is: in\n",
      "The age of the youth is: 16\n",
      "The race of the youth is: major\n",
      "The casegoal of the youth is: LTFC\n",
      "Current reward is: 0.1\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 17, 'major', 1, 'out']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step('a_R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status of the youth is: out\n",
      "The age of the youth is: 17\n",
      "The race of the youth is: major\n",
      "The casegoal of the youth is: R\n",
      "Current reward is: 1\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 18, 'major', 1, 'out']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step('a_R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 19, 'major', 1, 'out']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step('a_R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_trajectory(env,policy):\n",
    "    ## policy is epsilon greey policy\n",
    "    race = env.race\n",
    "    age = env.age\n",
    "    status = env.status\n",
    "    epsion = 0.1 # probability to sample a random action\n",
    "    trajectory = []\n",
    "    while status == 'in':\n",
    "        if np.random.binomial(1,epsion,1) == 1:\n",
    "            action = ['a_LTFC','a_R'][np.random.binomial(1,0.5,1)[0]]\n",
    "        else:\n",
    "            action = ['a_LTFC','a_R'][np.random.binomial(1,policy[(race,age)],1)[0]]\n",
    "        next_ = env.step(action)\n",
    "        status = next_[4]\n",
    "        age = next_[1]\n",
    "        reward = next_[3] \n",
    "        if status == 'out':\n",
    "            break\n",
    "        trajectory.append(((race,age),action, reward))\n",
    "    env.reset()\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(('major', 19), 'a_R')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a4acbee9039b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgamma_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mreturns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (('major', 19), 'a_R')"
     ]
    }
   ],
   "source": [
    "'''\n",
    "First version of model where reuntificaiton rates are constant. Rate_major = 0.5, rate_minor = 0.3, since the state is \n",
    "finate and generating samples are easilier than obtaining the distrbution in explicit form, monte carlo methods are\n",
    "suitable for solving this problem. However, as the state becomes more and more \n",
    "complex, advancend methods need to be used to solve this problem. \n",
    "'''\n",
    "\n",
    "## Sample a test group. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## On-policy first-visit MC control  Check Sutton et al. page 99 for details. \n",
    "\n",
    "state_ = list(itertools.product(['major','minor'],[3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]))\n",
    "np.random.seed(1)\n",
    "p = np.random.uniform(0,1,len(state_))\n",
    "policy = dict(zip(state_,p)) # sample a start policy. Is the probability to choose a_R\n",
    "# theta_ = 0.1\n",
    "gamma_ = 0.9 # discount factor\n",
    "q_value_ = dict(zip(list(itertools.product(state_,['a_LTFC','a_R'])), np.random.uniform(0,1,len(state_ ) * 2 )))\n",
    "returns = dict(zip(list(itertools.product(state_,['a_LTFC','a_R'])),([] for _ in range(len(state_) * 2) ) ))\n",
    "n = 0\n",
    "\n",
    "\n",
    "while n< 2000: ## iterate 2000 times. \n",
    "    n += 1 \n",
    "    trajectory = sample_trajectory(env,policy)\n",
    "    G = 0\n",
    "    trajectory.reverse()\n",
    "    returns = dict(zip(list(itertools.product(state_,['a_LTFC','a_R'])),([] for _ in range(len(state_) * 2) ) ))\n",
    "    for index, i in enumerate(trajectory):\n",
    "        state = i[0]\n",
    "        action = i[1]\n",
    "        reward = i[2]\n",
    "        G = G * gamma_ + reward\n",
    "        returns[(state,action)].append(G)\n",
    "    for k,v in returns.items():\n",
    "        if len(v) != 0: \n",
    "            q_value_[k] = np.mean(v)\n",
    "            if q_value_[(k[0],'a_LTFC')] > q_value_[(k[0],'a_R')]:\n",
    "                policy[k] = 0\n",
    "            else:\n",
    "                policy[k] = 1\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample a test population to check if policy improves over all reward and \n",
    "number = 10000\n",
    "\n",
    "age_p = [0.05699999999999994,0.08,0.08,0.08,0.07,0.06,0.06,0.05,0.05,0.06,0.07,0.08,0.09,0.08,0.03,0.003]\n",
    "age = [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "age_sample = np.random.multinomial(1,age_p,10000)\n",
    "self.age = age[np.where(age_sample == 1)[1][0]]\n",
    "## Sample race of the youth\n",
    "self.race = ['major','minor'][np.random.binomial(1,0.3,1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('major', 19), 'a_R', 0),\n",
       " (('major', 18), 'a_R', 0),\n",
       " (('major', 17), 'a_R', 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sample_trajectory(env,policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.81 * 0.9 + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-pytorch36]",
   "language": "python",
   "name": "conda-env-miniconda3-pytorch36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
